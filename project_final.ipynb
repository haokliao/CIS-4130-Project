{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIS 4130 Semester Project\n",
    "\n",
    "Our semester long project was to build a machine learning pipeline for our Big Data Technologies class.\n",
    "This pipeline incorporates cloud infrastructure, in our case utilizing different aspects of AWS such as EC2 instances and EMR clusters.\n",
    "\n",
    "This project is divided into five different Milestones, all with their own components and requirements!\n",
    "\n",
    "> Milestone 1: Project Proposal\n",
    "\n",
    "> Milestone 2: Data Acquisition\n",
    "\n",
    "> Milestone 3: Descriptive Statistics\n",
    "\n",
    "> Milestone 4: Coding and Modeling\n",
    "\n",
    "> Milestone 5: Visualizing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Milestone 1: Project Proposal\n",
    "\n",
    "The first milestone was doing research and looking for a dataset over 10GB. In our case, we decided to use the Yelp Dataset located [here](https://www.kaggle.com/datasets/yelp-dataset/yelp-dataset?resource=download&select=yelp_academic_dataset_business.json)\n",
    "\n",
    "This dataset consists of five different files:\n",
    "- business.json\n",
    "- checkin.json\n",
    "- review.json\n",
    "- tip.json\n",
    "- user.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Milestone 2: Data Acquisition\n",
    "\n",
    "The second milestone was to download this data directly into a S3 bucket\n",
    "\n",
    "We'll need to install the Kaggle api through `pip3 install kaggle`\n",
    "\n",
    "And create a new API Token in Kaggle. Through https://kaggle.com\n",
    "After logging in, and going to the Account page, scroll down to the API section and Create a New API Token.\n",
    "\n",
    "A `kaggle.json` file will be downloaded; open this file up in Notepad and copy contents to your clipboard.\n",
    "\n",
    "After this is done, follow the instructions in the `Steps for downloading data directly from Kaggle to AWS.docx` file regarding set up with your kaggle API files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an s3 bucket for project data\n",
    "aws s3api create-bucket --bucket project-data-hkl --region us-east-2 --create-bucket-configuration \\\n",
    "LocationConstraint=us-east-2\n",
    "\n",
    "# download yelp dataset off kaggle\n",
    "kaggle datasets download --quiet -d yelp-dataset/yelp-dataset -p -  | aws s3 cp - s3://project-data-hkl/yelp.zip\n",
    "\n",
    "# verify the download\n",
    "aws s3 ls s3://project-data-hkl/\n",
    "\n",
    "# once these files are downloaded, we'll have to unzip them, and reupload to the s3 bucket\n",
    "\n",
    "import zipfile\n",
    "import boto3 \n",
    "from io import BytesIO \n",
    "bucket=\"project-data-hkl\"\n",
    "zipfile_to_unzip=\"yelp.zip\"\n",
    "s3_client = boto3.client('s3', use_ssl=False) \n",
    "s3_resource = boto3.resource('s3')\n",
    "zip_obj = s3_resource.Object(bucket_name=bucket, key=zipfile_to_unzip) \n",
    "buffer = BytesIO(zip_obj.get()[\"Body\"].read()) \n",
    "z = zipfile.ZipFile(buffer) \n",
    "# Loop through all of the files contained in the Zip archive \n",
    "for filename in z.namelist():\n",
    "  print('Working on ' + filename)\n",
    "s3_resource.meta.client.upload_fileobj(z.open(filename), Bucket=bucket, Key=f'{filename}')\n",
    "\n",
    "# once again, check that these files were unzipped and uploaded to the bucket\n",
    "aws s3 ls s3://project-data-hkl/\n",
    "\n",
    "# here's some quick summary statistics we can perform to double check our data's all there\n",
    "import boto3\n",
    "import pandas as pd\n",
    "s3 = boto3.resource('s3')\n",
    "df = pd.read_json('s3://project-data-hkl/yelp_academic_dataset_business.json', lines=True)\n",
    "df.dtypes\n",
    "results = df.groupby('state').stars.agg(['count', 'mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Milestone 3: Descriptive Statistics\n",
    "\n",
    "In this milestone, we're going to better understand our data by performing some simple statistics:\n",
    "\n",
    "- df.dtypes gives us the datatypes for our columns, so we can find the numeric variables\n",
    "- df.count() gives us the numbers of values in the dataframe for each column\n",
    "- df.isna().sum() gives us the count for all missing values in the dataframe\n",
    "- df.dtypes shows us that which fields contain numeric values \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "business_df = pd.read_json('s3://project-data-hkl/yelp_academic_dataset_business.json', lines=True)\n",
    "business_df.dtypes\n",
    "business_df.count()\n",
    "business_df.isna().sum()\n",
    "business_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "tip_df = pd.read_json('s3://project-data-hkl/yelp_academic_dataset_tip.json', lines=True)\n",
    "tip_df.dtypes\n",
    "tip_df.count()\n",
    "tip_df.isna().sum()\n",
    "tip_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "user_df = pd.read_json('s3://project-data-hkl/yelp_academic_dataset_user.json', lines=True)\n",
    "user_df.dtypes\n",
    "user_df.count()\n",
    "user_df.isna().sum()\n",
    "user_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "review_df = pd.read_json('s3://project-data-hkl/yelp_academic_dataset_review.json', lines=True)\n",
    "review_df.dtypes\n",
    "review_df.count()\n",
    "review_df.isna().sum()\n",
    "review_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Milestone 4: Coding and Modeling\n",
    "\n",
    "On our review dataset, we'll be performing a linear regression to describe a relationship between number of stars a review has and the number of useful reviews that other rate that review.\n",
    "\n",
    "To do this, I borrowed methods from [Sanjjushri Varshini R](https://medium.com/featurepreneur/linear-regression-with-pyspark-in-10-steps-c6b3263a2c4) and [Susan Li](https://towardsdatascience.com/building-a-linear-regression-with-pyspark-and-mllib-d065c3ba246a) to help me with my linear regressions in PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"s3://project-data-hkl/yelp_academic_dataset_review.json\")\n",
    "df.printSchema()\n",
    "df.na.drop(\"any\").show(truncate=false)\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "vectorAssembler = VectorAssembler(inputCols = ['useful'], outputCol = 'features')\n",
    "vhouse_df = vectorAssembler.transform(df)\n",
    "vhouse_df = vhouse_df.select(['features', 'stars'])\n",
    "vhouse_df.show(3)\n",
    "\n",
    "splits = vhouse_df.randomSplit([0.7, 0.3])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]\n",
    "\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='stars')\n",
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))\n",
    "\n",
    "pred_results = lr_model.evaluate(test_df)\n",
    "output_file_path=\" s3://project-data-hkl/yelp_academic_dataset_review.json \"\n",
    "pred_results.write.options(header=\"True\", delimiter='\\t').csv(output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Milestone 5: Visualizing Results\n",
    "\n",
    "In this milestone, we performed visualizations utilizing PySpark and Python alone, with just the business dataset.\n",
    "This code is made to be run with an EMR Spark Cluster with 5 clusters.\n",
    "\n",
    "For our EMR cluster, we plan on joining the Reviews and Business datasets, into one central dataframe, `yelp_sdf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first install the packages that we're working with\n",
    "pip install matplotlib\n",
    "pip install pandas\n",
    "pip install s3fs\n",
    "\n",
    "#run our pyspark instance\n",
    "pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from pyspark.sql.functions import *\n",
    "import io\n",
    "import pandas as pd\n",
    "import s3fs \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yelp Reviews Dataset  \n",
    "reviews_filename = \"s3://project-data-hkl/yelp_academic_dataset_review.json\"\n",
    "reviews_sdf = spark.read.json(reviews_filename)\n",
    "# Rename the stars with review_stars\n",
    "reviews_sdf = reviews_sdf.withColumnRenamed('stars', 'review_stars')\n",
    "# Rename the 'date' column with 'review_date'\n",
    "reviews_sdf = reviews_sdf.withColumnRenamed('date', 'review_date')\n",
    "# Convert review_date to an actual date data type\n",
    "reviews_sdf = reviews_sdf.withColumn(\"review_date\", to_date(to_timestamp(col(\"review_date\"), \"yyyy-MM-dd HH:mm:ss\" )) )\n",
    "# Get the age of the review in days\n",
    "reviews_sdf = reviews_sdf.withColumn(\"review_age_days\", datediff(current_date(),col(\"review_date\")) )\n",
    "reviews_sdf = reviews_sdf.withColumn(\"review_age_years\", col(\"review_age_days\")/365.0 )\n",
    "reviews_sdf = reviews_sdf.withColumn(\"review_year\", year(\"review_date\") )\n",
    "\n",
    "# Likely don't need the review_id\n",
    "reviews_sdf = reviews_sdf.drop('review_id')\n",
    "\n",
    "# Create an indicator variable if the star rating is more than 3.0\n",
    "reviews_sdf = reviews_sdf.withColumn(\"goodreview\", when(col(\"review_stars\") > 3.0, 1.0).otherwise(0.0))\n",
    "\n",
    "# Yelp Businesses Dataset\n",
    "business_filename = \"s3://project-data-hkl/yelp_academic_dataset_business.json\"\n",
    "business_sdf = spark.read.json(business_filename)\n",
    "business_sdf.printSchema()\n",
    "# Rename the business \"stars\"\n",
    "business_sdf = business_sdf.withColumnRenamed('stars', 'business_stars')\n",
    "business_sdf.select(\"business_id\", \"name\", \"categories\", \"attributes.Alcohol\", \"attributes.NoiseLevel\").show()\n",
    "\n",
    "# Grab some columns we likely want to explore\n",
    "business_sdf = business_sdf.withColumn(\"alcohol\", business_sdf.attributes.Alcohol)\n",
    "\n",
    "# Drop some columns we likely don't need\n",
    "business_sdf = business_sdf.drop('city','hours','is_open','latitude','longitude','postal_code','state','address','attributes')\n",
    "\n",
    "# Fill in missing / null values\n",
    "business_sdf = business_sdf.withColumn('alcohol', when(lower(business_sdf.alcohol) == 'none', None).otherwise(business_sdf.alcohol))\n",
    "business_sdf = business_sdf.withColumn('alcohol', when(lower(business_sdf.alcohol) == \"'none'\", None).otherwise(business_sdf.alcohol))\n",
    "business_sdf = business_sdf.withColumn('alcohol', when(lower(business_sdf.alcohol) == u'none', None).otherwise(business_sdf.alcohol))\n",
    "business_sdf = business_sdf.withColumn('alcohol', when(lower(business_sdf.alcohol) == \"u'none'\", None).otherwise(business_sdf.alcohol))\n",
    "business_sdf = business_sdf.withColumn('alcohol', when(lower(business_sdf.alcohol) == \"'beer_and_wine'\", \"beer_and_wine\").otherwise(business_sdf.alcohol))\n",
    "business_sdf = business_sdf.withColumn('alcohol', when(lower(business_sdf.alcohol) == \"u'beer_and_wine'\", \"beer_and_wine\").otherwise(business_sdf.alcohol))\n",
    "business_sdf = business_sdf.withColumn('alcohol', when(lower(business_sdf.alcohol) == \"'full_bar'\", \"full_bar\").otherwise(business_sdf.alcohol))\n",
    "business_sdf = business_sdf.withColumn('alcohol', when(lower(business_sdf.alcohol) == \"u'full_bar'\", \"full_bar\").otherwise(business_sdf.alcohol))\n",
    "\n",
    "# Join business with reviews\n",
    "yelp_sdf = reviews_sdf.join(business_sdf, \"business_id\")\n",
    "yelp_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe shape\n",
    "#  |-- business_id: string (nullable = true)\n",
    "#  |-- cool: long (nullable = true)\n",
    "#  |-- review_date: date (nullable = true)\n",
    "#  |-- funny: long (nullable = true)\n",
    "#  |-- review_stars: double (nullable = true)\n",
    "#  |-- text: string (nullable = true)\n",
    "#  |-- useful: long (nullable = true)\n",
    "#  |-- user_id: string (nullable = true)\n",
    "#  |-- review_age_days: integer (nullable = true)\n",
    "#  |-- review_age_years: double (nullable = true)\n",
    "#  |-- goodreview: double (nullable = false)\n",
    "#  |-- categories: string (nullable = true)\n",
    "#  |-- name: string (nullable = true)\n",
    "#  |-- review_count: long (nullable = true)\n",
    "#  |-- business_stars: double (nullable = true)\n",
    "#  |-- alcohol: string (nullable = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reviews in the last 10 years\n",
    "year_count_df = yelp_sdf.where(col(\"review_year\") > 2012).groupby('review_year').count().sort('review_year').toPandas()\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.bar(year_count_df['review_year'], year_count_df['count'])\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Reviews\")\n",
    "plt.title(\"Number of Reviews after 2012 by Year\")\n",
    "plt.xticks(rotation=90, ha='right')\n",
    "fig.tight_layout()\n",
    "\n",
    "review_count_by_year = io.BytesIO()\n",
    "plt.savefig(review_count_by_year, format='png', bbox_inches='tight')\n",
    "review_count_by_year.seek(0)\n",
    "# Connect to the s3fs file system\n",
    "s3 = s3fs.S3FileSystem(anon=False)\n",
    "with s3.open('s3://project-data-hkl/review_count_by_year.png', 'wb') as f:\n",
    "  f.write(review_count_by_year.getbuffer())\n",
    "\n",
    "\n",
    "# Look at Total Star ratings\n",
    "star_count_df = yelp_sdf.groupBy(\"review_stars\").count().sort(\"review_stars\").toPandas()\n",
    "fig = plt.figure()\n",
    "plt.ticklabel_format(useOffset=False, style='plain', axis='y')\n",
    "plt.bar(star_count_df['review_stars'],star_count_df['count'] )\n",
    "# fig.tight_layout()\n",
    "plt.title(\"Review Count by Star Rating\")\n",
    "star_rating_count = io.BytesIO()\n",
    "plt.savefig(star_rating_count, format='png', bbox_inches='tight')\n",
    "star_rating_count.seek(0)\n",
    "# Connect to the s3fs file system\n",
    "s3 = s3fs.S3FileSystem(anon=False)\n",
    "with s3.open('s3://project-data-hkl/star_rating_count.png', 'wb') as f:\n",
    "  f.write(star_rating_count.getbuffer())\n",
    "\n",
    "# Good restaurants that serve alcohol?\n",
    "alcohol_df = yelp_sdf.where(col(\"goodreview\") != '0').groupby('alcohol').count().sort('alcohol').toPandas()\n",
    "alcohol_df['alcohol'].replace({None:'None'},inplace=True)\n",
    "fig = plt.figure()\n",
    "plt.ticklabel_format(useOffset=False, style='plain', axis='y')\n",
    "plt.bar(alcohol_df['alcohol'], alcohol_df['count'])\n",
    "plt.xlabel(\"Alcohol Service\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Number of Restaurants with Good Reviews (>3.0) That Serve Alcohol?\")\n",
    "\n",
    "good_review = io.BytesIO()\n",
    "plt.savefig(good_review, format='png', bbox_inches='tight')\n",
    "good_review.seek(0)\n",
    "# Connect to the s3fs file system\n",
    "s3 = s3fs.S3FileSystem(anon=False)\n",
    "with s3.open('s3://project-data-hkl/good_review_alcohol.png', 'wb') as f:\n",
    "  f.write(good_review.getbuffer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Visualization Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import s3fs \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "\n",
    "df = pd.read_json('yelp_academic_dataset_business.json', lines=True)\n",
    "\n",
    "#dropping restaurants in states with just one restaurant\n",
    "df.loc[df['categories'].str.contains('Restaurant',case=False,na=False),'is_restaurant'] = 'Yes'\n",
    "df.loc[~df['categories'].str.contains('Restaurant',case=False,na=False),'is_restaurant'] = 'No'\n",
    "restaurant_df = df[df['is_restaurant']=='Yes']\n",
    "restaurant_df = restaurant_df[~(restaurant_df.state.isin(['XMS','MT','NC','HI','CO']))]\n",
    "\n",
    "#average reviews over time\n",
    "restaurant_df['review_year'] = restaurant_df[review_date].dt.year\n",
    "restaurant_rating_over_time = restaurant_df.groupby(['stars','review_year']).reset_index().round(2)\n",
    "\n",
    "is_restaurant = df['is_restaurant'].value_counts().reset_index().rename(columns={'index':'is_restaurant','is_restaurant':'count'})\n",
    "is_restaurant\n",
    "fig1 = plt.figure()\n",
    "plt.barh(is_restaurant['is_restaurant'],is_restaurant['count'])\n",
    "plt.title(\"Number of Restaurants in Dataset\")\n",
    "\n",
    "# Create a buffer to hold the figure\n",
    "img_data = io.BytesIO()\n",
    "# Write the figure to the buffer\n",
    "plt.savefig(img_data, format='png', bbox_inches='tight')\n",
    "img_data.seek(0)\n",
    "# Connect to the s3fs file system\n",
    "s3 = s3fs.S3FileSystem(anon=False)\n",
    "with s3.open('s3://project-data-hkl/restaurant_count.png', 'wb') as f:\n",
    "  f.write(img_data.getbuffer())\n",
    "\n",
    "######\n",
    "avg_stars = restaurant_df.groupby(['state',])['stars'].mean().round(decimals=2).reset_index(name='average')\n",
    "avg_stars = avg_stars.sort_values(by='average',ascending=False)\n",
    "avg_stars\n",
    "\n",
    "# Create a buffer to hold the figure\n",
    "img_data = io.BytesIO()\n",
    "# Write the figure to the buffer\n",
    "plt.savefig(img_data, format='png', bbox_inches='tight')\n",
    "img_data.seek(0)\n",
    "# Connect to the s3fs file system\n",
    "s3 = s3fs.S3FileSystem(anon=False)\n",
    "with s3.open('s3://project-data-hkl/average_restaurant_review_state.png', 'wb') as f:\n",
    "  f.write(img_data.getbuffer())\n",
    "\n",
    "ca_rest_df = restaurant_df[restaurant_df['state']=='CA']\n",
    "restaurant_review_ct = ca_rest_df.groupby(['state','stars'])['business_id'].count().reset_index(name='count')\n",
    "restaurant_review_ct\n",
    "\n",
    "fig2 = plt.figure(figsize=(9,6))\n",
    "plt.bar(restaurant_review_ct['stars'],restaurant_review_ct['count'],width=.4)\n",
    "plt.title(\"Most Frequent Star Ratings in California\")\n",
    "\n",
    "# Create a buffer to hold the figure\n",
    "img_data = io.BytesIO()\n",
    "# Write the figure to the buffer\n",
    "plt.savefig(img_data, format='png', bbox_inches='tight')\n",
    "img_data.seek(0)\n",
    "# Connect to the s3fs file system\n",
    "s3 = s3fs.S3FileSystem(anon=False)\n",
    "with s3.open('s3://project-data-hkl/frequent_stars_rating_ca.png', 'wb') as f:\n",
    "  f.write(img_data.getbuffer())\n",
    "\n",
    "#Let's say a good indicator of a restaurant is above 4.0 stars! What city has the most of these restaurants?\n",
    "four_star_ca_restaurants = ca_rest_df[ca_rest_df['stars']>= 4.0]\n",
    "\n",
    "four_star_ca_restaurants_cnt = four_star_ca_restaurants.groupby(['city'])['stars'].count().reset_index(name='count')\n",
    "four_star_ca_restaurants_cnt = four_star_ca_restaurants_cnt[four_star_ca_restaurants_cnt['count']!=1]\n",
    "four_star_ca_restaurants_cnt\n",
    "\n",
    "fig2 = plt.figure(figsize=(9,6))\n",
    "plt.bar(four_star_ca_restaurants_cnt['city'],four_star_ca_restaurants_cnt['count'],width=.4)\n",
    "plt.title(\"California Cities with Best Reviewed Restaurants\")\n",
    "plt.show()\n",
    "\n",
    "# Create a buffer to hold the figure\n",
    "img_data = io.BytesIO()\n",
    "# Write the figure to the buffer\n",
    "plt.savefig(img_data, format='png', bbox_inches='tight')\n",
    "img_data.seek(0)\n",
    "# Connect to the s3fs file system\n",
    "s3 = s3fs.S3FileSystem(anon=False)\n",
    "with s3.open('s3://project-data-hkl/ca_best_reviewed.png', 'wb') as f:\n",
    "  f.write(img_data.getbuffer())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
